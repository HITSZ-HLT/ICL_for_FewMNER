{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(data_true, chatgpt_pred):\n",
    "    name_list = [\"person\", \"organization\", \"location\", \"miscellaneous\"]\n",
    "    all_truth_entity,hit_entity,all_pred_entity = 0,0,0\n",
    "    label_entity_all, pred_entity_all = [], []\n",
    "    category_result = {}\n",
    "    entity_notin_sentence = []\n",
    "    for name in name_list:\n",
    "        category_result[name] = {}\n",
    "        category_result[name][\"single_hit\"] = 0\n",
    "        category_result[name][\"single_pred\"] = 0\n",
    "        category_result[name][\"single_true\"] = 0\n",
    "\n",
    "    for i in range(len(chatgpt_pred)):\n",
    "        sentence = chatgpt_pred.loc[i, \"text\"]\n",
    "        for name in name_list:\n",
    "            truth_entity = data_true.loc[i, name]\n",
    "            pred_entity = chatgpt_pred.loc[i, name]\n",
    "            truth_entity_list = literal_eval(truth_entity)\n",
    "            pred_entity_list = literal_eval(pred_entity)\n",
    "            new_truth_list = truth_entity_list\n",
    "            single_hit, single_pred, single_true = 0, 0, 0\n",
    "            if pred_entity_list == ['None']:\n",
    "                new_pred_list = []\n",
    "            else:\n",
    "                new_pred_list = pred_entity_list\n",
    "                \n",
    "            for index in range(len(new_pred_list)):\n",
    "                if str(new_pred_list[index]) not in sentence:\n",
    "                    entity_notin_sentence.append(new_pred_list[index])\n",
    "                else:\n",
    "                    if new_pred_list[index] in new_truth_list:\n",
    "                        hit_entity += 1\n",
    "                        single_hit += 1\n",
    "                    all_pred_entity += 1\n",
    "                    single_pred += 1\n",
    "                    \n",
    "            for index in range(len(new_truth_list)):\n",
    "                if new_truth_list[index] != []:\n",
    "                    all_truth_entity += 1\n",
    "                    single_true += 1\n",
    "            label_entity_all.append(new_truth_list)\n",
    "            pred_entity_all.append(new_pred_list)\n",
    "            category_result[name][\"single_hit\"] += single_hit\n",
    "            category_result[name][\"single_pred\"] += single_pred\n",
    "            category_result[name][\"single_true\"] += single_true\n",
    "\n",
    "    P = hit_entity/all_pred_entity\n",
    "    R = hit_entity/all_truth_entity\n",
    "    F1 = 2*P*R/(P+R)\n",
    "\n",
    "    result = {}\n",
    "    result[\"all_truth_entity\"] = all_truth_entity\n",
    "    result[\"all_pred_entity\"] = all_pred_entity\n",
    "    result[\"hit_entity\"] = hit_entity\n",
    "    result[\"P\"] = P\n",
    "    result[\"R\"] = R\n",
    "    result[\"F1\"] = F1\n",
    "    print(\"entity not in sentence:\", len(entity_notin_sentence))\n",
    "    for name in name_list:\n",
    "        category_result[name][\"P\"] = category_result[name][\"single_hit\"]/category_result[name][\"single_pred\"]\n",
    "        category_result[name][\"R\"] = category_result[name][\"single_hit\"]/category_result[name][\"single_true\"]\n",
    "        category_result[name][\"F1\"] = 2*category_result[name][\"P\"]*category_result[name][\"R\"]/(category_result[name][\"P\"]+category_result[name][\"R\"])\n",
    "    return result, pred_entity_all, label_entity_all, category_result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entity not in sentence: 576\n",
      "all_truth_entity: 5116\n",
      "all_pred_entity: 6896\n",
      "hit_entity: 3370\n",
      "P: 0.4886890951276102\n",
      "R: 0.6587177482408131\n",
      "F1: 0.5611055611055611\n",
      "person: {'single_hit': 1508, 'single_pred': 2075, 'single_true': 1825, 'P': 0.7267469879518073, 'R': 0.8263013698630137, 'F1': 0.7733333333333334}\n",
      "organization: {'single_hit': 550, 'single_pred': 2015, 'single_true': 839, 'P': 0.2729528535980149, 'R': 0.6555423122765197, 'F1': 0.38542396636299936}\n",
      "location: {'single_hit': 1126, 'single_pred': 1689, 'single_true': 1728, 'P': 0.6666666666666666, 'R': 0.6516203703703703, 'F1': 0.6590576529119111}\n",
      "miscellaneous: {'single_hit': 186, 'single_pred': 1117, 'single_true': 724, 'P': 0.1665174574753805, 'R': 0.2569060773480663, 'F1': 0.2020640956002173}\n"
     ]
    }
   ],
   "source": [
    "# multiMM_gpt3.5_twitter2017_50-1_shot-4\n",
    "chatgpt_pred = pd.read_csv(\"multiMM_gpt3.5_twitter2015_50-1_shot-4_predict_test.csv\", sep=\"\\t\")\n",
    "data_true = pd.read_csv(\"./obtain_image_caption/twitter2015_process_caption_test.csv\", sep=\"\\t\")\n",
    "chatgpt_pred = chatgpt_pred.fillna(\"['None']\")\n",
    "result, pred_entity_all, label_entity_all, category_result = metric(data_true, chatgpt_pred)\n",
    "for k in result:\n",
    "    print(k + \":\", result[k])\n",
    "for k in category_result:\n",
    "    print(k + \":\", category_result[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ricky",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
